{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this hands on you will be using Gated Recurrent Units to predict the airline passenger count in a given month based on the information from previous months.\n",
    "\n",
    "- Follow the instructions provided for each cell and and code accordingly. \n",
    "- In order to run the cell press shift+enter.\n",
    "- make sure you have run all the cells before submitting the hands on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the below cell to import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read data from air_line.csv file using pandas and assign the values of \"passenger_count\" column to variable **dataset**, \n",
    "- typecast passenger count values values to float32\n",
    "### Expected output\n",
    "[[112.]\n",
    " [118.]\n",
    " [132.]\n",
    " [129.]\n",
    " [121.]\n",
    " [135.]\n",
    " [148.]\n",
    " [148.]\n",
    " [136.]\n",
    " [119.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Start code here\n",
    "dataset = \n",
    "###End code\n",
    "#dataset = dataset.astype('float32')\n",
    "print(dataset[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use MinMaxScaler to normalize the values of **dataset** between the range 0 to 1  \n",
    "### Expected output\n",
    "[[0.01544401]\n",
    " [0.02702703]\n",
    " [0.05405405]\n",
    " [0.04826255]\n",
    " [0.03281853]\n",
    " [0.05984557]\n",
    " [0.08494207]\n",
    " [0.08494207]\n",
    " [0.06177607]\n",
    " [0.02895753]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Start code here\n",
    "\n",
    "dataset = \n",
    "###End code\n",
    "print(dataset[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split the dataset  \n",
    "- Assign to first 100 values of dataset to variable **train** and remaining values to variable **test**\n",
    "### Expected output:\n",
    "100 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Start code here\n",
    "\n",
    "train, test = \n",
    "###End code\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write a function to generate training dataset \n",
    "    - parameters: dataset: orginal dataset\n",
    "                  look_back: the window size that tells the number of previous values in the series to look for to                   predict the next one.\n",
    "    - returns: feature and target arrays\n",
    "\n",
    "example: \n",
    "         for window size 1:\n",
    "         dataset = [1,2,3,4]  \n",
    "         feature = [[1],[2],[3]]    \n",
    "         target = [2,3,4]  \n",
    "         \n",
    "         for window size 2:\n",
    "         feature = [[1,2],[2,3]]  \n",
    "         target = [3,4]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Start code\n",
    "def generate_dataset(dataset, look_back=1):\n",
    "    \n",
    "    \n",
    "    \n",
    "###End code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the below cell uses the method you defined above to generate feature and target datasets on train and teat data\n",
    "### Expected output:\n",
    "(98, 1)  \n",
    "(98,)  \n",
    "(42, 1)  \n",
    "(42,)  \n",
    "[[0.01544401]  \n",
    " [0.02702703]]  \n",
    "[0.02702703 0.05405405]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 1\n",
    "trainX, trainY = generate_dataset(train, look_back)\n",
    "testX, testY = generate_dataset(test, look_back)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)\n",
    "print(trainX[:2])\n",
    "print(trainY[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the trainX and testX dataset to (number of samples, 1, look_back)\n",
    "\n",
    "### Expected output:\n",
    "(98, 1, 1)  \n",
    "(98,)  \n",
    "(42, 1, 1)  \n",
    "(42,)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Start code here\n",
    "trainX = \n",
    "testX = \n",
    "###End code\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using keras Sequential() class create a model having one GRU block and one dense layer\n",
    "### compile the model with mean_squared_error loss adam optimizer\n",
    "\n",
    "### Expected output\n",
    "<img src = summary.png/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(51)\n",
    "###Start code here\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "###End code\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model.fit() on train data for 30 epoches and batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Start code\n",
    "\n",
    "###End code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using model.predict assign the predicted output on trainX and test X to trainPredicy and testPredict variables respectively\n",
    "#### since the data was normalized previously invert the values to their original form (hint: use .invert_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Start code here\n",
    "trainPredict = \n",
    "\n",
    "testPredict = \n",
    "\n",
    "trainPredict = \n",
    "trainY = \n",
    "testPredict = \n",
    "testY = \n",
    "###End code\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "with open(\"output.txt\", \"w+\") as file:\n",
    "    file.write(\"train score {0:.2f}\\n\".format(trainScore))\n",
    "    file.write(\"test score {0:.2f}\".format(testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the below cell to plot the train as well as predicted passenger counts.\n",
    "### you can observe that the predicted results follow the same trend as of train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
